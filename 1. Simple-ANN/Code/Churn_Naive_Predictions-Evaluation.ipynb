{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../Data/Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_encode_country = LabelEncoder()\n",
    "label_encode_Gender = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X[:,1] = label_encode_country.fit_transform(X[:,1])\n",
    "X[:,2] = label_encode_Gender.fit_transform(X[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onehot = OneHotEncoder(categorical_features=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = onehot.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = sc.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ab/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_classifier():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=6,kernel_initializer='uniform',activation='relu',input_dim=11))\n",
    "    model.add(Dense(units=6,kernel_initializer='uniform',activation='relu'))\n",
    "    model.add(Dense(units=1,kernel_initializer='uniform',activation='sigmoid'))\n",
    "    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=build_classifier, batch_size=10,nb_epoch= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 436us/step - loss: 0.4948 - acc: 0.7974\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 440us/step - loss: 0.4915 - acc: 0.7974\n",
      "6190/7200 [========================>.....] - ETA: 0s - loss: 0.5043 - acc: 0.7961Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 466us/step - loss: 0.4931 - acc: 0.7965\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 4s 493us/step - loss: 0.4942 - acc: 0.7958\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 388us/step - loss: 0.4312 - acc: 0.7982\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 410us/step - loss: 0.4290 - acc: 0.7975\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 477us/step - loss: 0.4285 - acc: 0.7982\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 462us/step - loss: 0.4319 - acc: 0.7967\n",
      " 470/7200 [>.............................] - ETA: 3s - loss: 0.4128 - acc: 0.7936Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 419us/step - loss: 0.4270 - acc: 0.7982\n",
      "4430/7200 [=================>............] - ETA: 1s - loss: 0.4282 - acc: 0.7948Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 373us/step - loss: 0.4241 - acc: 0.7975\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 430us/step - loss: 0.4240 - acc: 0.7982\n",
      "5940/7200 [=======================>......] - ETA: 0s - loss: 0.4267 - acc: 0.7968Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 459us/step - loss: 0.4270 - acc: 0.7967\n",
      "1310/7200 [====>.........................] - ETA: 2s - loss: 0.4183 - acc: 0.7924Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 406us/step - loss: 0.4227 - acc: 0.8017\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 466us/step - loss: 0.4192 - acc: 0.8087\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 423us/step - loss: 0.4198 - acc: 0.8119\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 350us/step - loss: 0.4226 - acc: 0.8082\n",
      "  10/7200 [..............................] - ETA: 2s - loss: 0.2399 - acc: 0.8000Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 424us/step - loss: 0.4204 - acc: 0.8233\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 420us/step - loss: 0.4169 - acc: 0.8249\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 366us/step - loss: 0.4174 - acc: 0.8269\n",
      "1130/7200 [===>..........................] - ETA: 2s - loss: 0.4034 - acc: 0.8283Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 474us/step - loss: 0.4205 - acc: 0.8233\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 394us/step - loss: 0.4190 - acc: 0.8272\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 382us/step - loss: 0.4152 - acc: 0.8282\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 466us/step - loss: 0.4159 - acc: 0.8292\n",
      "2000/7200 [=======>......................] - ETA: 2s - loss: 0.4177 - acc: 0.8290Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 467us/step - loss: 0.4189 - acc: 0.8282\n",
      "2150/7200 [=======>......................] - ETA: 1s - loss: 0.4080 - acc: 0.8400Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 460us/step - loss: 0.4175 - acc: 0.8275\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 441us/step - loss: 0.4136 - acc: 0.8301\n",
      "6360/7200 [=========================>....] - ETA: 0s - loss: 0.4091 - acc: 0.8336Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 385us/step - loss: 0.4141 - acc: 0.8311\n",
      "4640/7200 [==================>...........] - ETA: 1s - loss: 0.4237 - acc: 0.8280Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 422us/step - loss: 0.4171 - acc: 0.8286\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 414us/step - loss: 0.4126 - acc: 0.8326\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 421us/step - loss: 0.4128 - acc: 0.8331\n",
      " 790/7200 [==>...........................] - ETA: 2s - loss: 0.4284 - acc: 0.8228Epoch 9/10\n",
      "7200/7200 [==============================] - 4s 495us/step - loss: 0.4164 - acc: 0.8293\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 452us/step - loss: 0.4161 - acc: 0.8321\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 404us/step - loss: 0.4116 - acc: 0.8346\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 439us/step - loss: 0.4157 - acc: 0.8311\n",
      "1320/7200 [====>.........................] - ETA: 2s - loss: 0.4059 - acc: 0.8394Epoch 10/10\n",
      "7200/7200 [==============================] - 4s 501us/step - loss: 0.4122 - acc: 0.8346\n",
      "2440/7200 [=========>....................] - ETA: 1s - loss: 0.4131 - acc: 0.8357Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 366us/step - loss: 0.4152 - acc: 0.8314\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 419us/step - loss: 0.4106 - acc: 0.8344\n",
      "800/800 [==============================] - 0s 347us/steposs: 0.4178 - acc: 0.83\n",
      "7200/7200 [==============================] - 3s 473us/step - loss: 0.4145 - acc: 0.8314\n",
      "7200/7200 [==============================] - 3s 378us/step - loss: 0.4139 - acc: 0.8322\n",
      "7200/7200 [==============================] - 3s 422us/step - loss: 0.4109 - acc: 0.8354\n",
      "800/800 [==============================] - 0s 183us/step\n",
      "800/800 [==============================] - 0s 272us/step\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 0s 364us/step\n",
      "  70/7200 [..............................] - ETA: 49s - loss: 0.6923 - acc: 0.7143 Epoch 1/10\n",
      " 180/7200 [..............................] - ETA: 21s - loss: 0.6904 - acc: 0.7778Epoch 1/10\n",
      " 390/7200 [>.............................] - ETA: 11s - loss: 0.6861 - acc: 0.8128Epoch 1/10\n",
      "7200/7200 [==============================] - 4s 536us/step - loss: 0.4961 - acc: 0.7981\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 476us/step - loss: 0.4959 - acc: 0.7976\n",
      " 120/7200 [..............................] - ETA: 3s - loss: 0.4656 - acc: 0.7583Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 465us/step - loss: 0.4941 - acc: 0.7999\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 469us/step - loss: 0.4952 - acc: 0.7987\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 3s 405us/step - loss: 0.4210 - acc: 0.8068\n",
      "6850/7200 [===========================>..] - ETA: 0s - loss: 0.4214 - acc: 0.8061Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 410us/step - loss: 0.4097 - acc: 0.8100\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 449us/step - loss: 0.4208 - acc: 0.8064\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 454us/step - loss: 0.4108 - acc: 0.8083\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 3s 413us/step - loss: 0.4075 - acc: 0.8111\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 374us/step - loss: 0.3823 - acc: 0.8344\n",
      "6230/7200 [========================>.....] - ETA: 0s - loss: 0.3846 - acc: 0.8326Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 442us/step - loss: 0.4029 - acc: 0.8146\n",
      "7200/7200 [==============================] - 3s 451us/step - loss: 0.3830 - acc: 0.8339\n",
      "Epoch 4/10\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 3s 407us/step - loss: 0.3803 - acc: 0.8397\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 400us/step - loss: 0.3635 - acc: 0.8532\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 471us/step - loss: 0.3626 - acc: 0.8531\n",
      "6370/7200 [=========================>....] - ETA: 0s - loss: 0.3797 - acc: 0.8380Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 450us/step - loss: 0.3798 - acc: 0.8393\n",
      " 510/7200 [=>............................] - ETA: 4s - loss: 0.3837 - acc: 0.8373Epoch 5/10\n",
      "7200/7200 [==============================] - 3s 377us/step - loss: 0.3539 - acc: 0.8586\n",
      "7200/7200 [==============================] - 3s 439us/step - loss: 0.3594 - acc: 0.8569\n",
      "5890/7200 [=======================>......] - ETA: 0s - loss: 0.3562 - acc: 0.8577Epoch 6/10\n",
      "4930/7200 [===================>..........] - ETA: 1s - loss: 0.3647 - acc: 0.8515Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 446us/step - loss: 0.3531 - acc: 0.8581\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 3s 469us/step - loss: 0.3631 - acc: 0.8524\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 3s 397us/step - loss: 0.3493 - acc: 0.8618\n",
      "5020/7200 [===================>..........] - ETA: 0s - loss: 0.3599 - acc: 0.8546Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 416us/step - loss: 0.3498 - acc: 0.8607\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 402us/step - loss: 0.3502 - acc: 0.8597\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 366us/step - loss: 0.3562 - acc: 0.8553\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 3s 390us/step - loss: 0.3481 - acc: 0.8589\n",
      "4620/7200 [==================>...........] - ETA: 1s - loss: 0.3503 - acc: 0.8558Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 382us/step - loss: 0.3470 - acc: 0.8610\n",
      "4910/7200 [===================>..........] - ETA: 1s - loss: 0.3475 - acc: 0.8560Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 395us/step - loss: 0.3525 - acc: 0.8564\n",
      "1300/7200 [====>.........................] - ETA: 3s - loss: 0.3483 - acc: 0.8585Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 449us/step - loss: 0.3487 - acc: 0.8585\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 3s 383us/step - loss: 0.3439 - acc: 0.8628\n",
      "4490/7200 [=================>............] - ETA: 1s - loss: 0.3543 - acc: 0.8521Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 319us/step - loss: 0.3500 - acc: 0.8581\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 461us/step - loss: 0.3463 - acc: 0.8626\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 420us/step - loss: 0.3469 - acc: 0.8581\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 3s 390us/step - loss: 0.3424 - acc: 0.8612\n",
      "3340/7200 [============>.................] - ETA: 1s - loss: 0.3371 - acc: 0.8650Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 369us/step - loss: 0.3491 - acc: 0.8564\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 370us/step - loss: 0.3449 - acc: 0.8608\n",
      " 340/7200 [>.............................] - ETA: 4s - loss: 0.3037 - acc: 0.8912Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 458us/step - loss: 0.3461 - acc: 0.8587\n",
      "4090/7200 [================>.............] - ETA: 1s - loss: 0.3528 - acc: 0.8513Epoch 10/10\n",
      "7200/7200 [==============================] - 3s 396us/step - loss: 0.3417 - acc: 0.8639\n",
      "7200/7200 [==============================] - 3s 358us/step - loss: 0.3441 - acc: 0.8637\n",
      "800/800 [==============================] - 0s 355us/steposs: 0.3547 - acc: 0.85\n",
      "800/800 [==============================] - 0s 347us/step\n",
      "7200/7200 [==============================] - 3s 435us/step - loss: 0.3482 - acc: 0.8586\n",
      "800/800 [==============================] - 0s 233us/steposs: 0.3524 - acc: 0.85\n",
      "6610/7200 [==========================>...] - ETA: 0s - loss: 0.3456 - acc: 0.8598Epoch 1/10\n",
      "7000/7200 [============================>.] - ETA: 0s - loss: 0.3447 - acc: 0.8604Epoch 1/10\n",
      "7200/7200 [==============================] - 2s 295us/step - loss: 0.3451 - acc: 0.8603\n",
      "800/800 [==============================] - 0s 170us/step loss: 0.6931 - acc: 0.80\n",
      "7200/7200 [==============================] - 2s 256us/step - loss: 0.4972 - acc: 0.8004\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 267us/step - loss: 0.4993 - acc: 0.7951\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 225us/step - loss: 0.4314 - acc: 0.8003\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 211us/step - loss: 0.4351 - acc: 0.7950\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 215us/step - loss: 0.4277 - acc: 0.8003\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 239us/step - loss: 0.4301 - acc: 0.7950\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 220us/step - loss: 0.4250 - acc: 0.8003\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 214us/step - loss: 0.4262 - acc: 0.7964\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 231us/step - loss: 0.4216 - acc: 0.8089\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 205us/step - loss: 0.4222 - acc: 0.8192\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 215us/step - loss: 0.4186 - acc: 0.8253\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 226us/step - loss: 0.4193 - acc: 0.8274\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 200us/step - loss: 0.4169 - acc: 0.8285\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 226us/step - loss: 0.4175 - acc: 0.8304\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 233us/step - loss: 0.4156 - acc: 0.8319\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 221us/step - loss: 0.4163 - acc: 0.8310\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 226us/step - loss: 0.4139 - acc: 0.8332\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 215us/step - loss: 0.4137 - acc: 0.8322\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 209us/step - loss: 0.4105 - acc: 0.8335\n",
      "7200/7200 [==============================] - 2s 239us/step - loss: 0.4130 - acc: 0.8326\n",
      "800/800 [==============================] - 0s 182us/step\n",
      "800/800 [==============================] - 0s 139us/step\n"
     ]
    }
   ],
   "source": [
    "accuracies = cross_val_score(estimator=model, X=x_train, y=y_train,cv=10,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.83874999,  0.82625   ,  0.8475    ,  0.825     ,  0.87249999,\n",
       "        0.86624999,  0.83749999,  0.84624999,  0.8275    ,  0.84749999])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84349999453872448"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00023524997415393846"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015337860807620418"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=6,kernel_initializer='uniform',activation='relu',input_dim=11))\n",
    "model.add(Dropout(rate=0.1))\n",
    "model.add(Dense(units=6,kernel_initializer='uniform',activation='relu'))\n",
    "model.add(Dropout(rate=0.1))\n",
    "model.add(Dense(units=1,kernel_initializer='uniform',activation='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Dropout in module keras.layers.core:\n",
      "\n",
      "class Dropout(keras.engine.topology.Layer)\n",
      " |  Applies Dropout to the input.\n",
      " |  \n",
      " |  Dropout consists in randomly setting\n",
      " |  a fraction `rate` of input units to 0 at each update during training time,\n",
      " |  which helps prevent overfitting.\n",
      " |  \n",
      " |  # Arguments\n",
      " |      rate: float between 0 and 1. Fraction of the input units to drop.\n",
      " |      noise_shape: 1D integer tensor representing the shape of the\n",
      " |          binary dropout mask that will be multiplied with the input.\n",
      " |          For instance, if your inputs have shape\n",
      " |          `(batch_size, timesteps, features)` and\n",
      " |          you want the dropout mask to be the same for all timesteps,\n",
      " |          you can use `noise_shape=(batch_size, 1, features)`.\n",
      " |      seed: A Python integer to use as random seed.\n",
      " |  \n",
      " |  # References\n",
      " |      - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dropout\n",
      " |      keras.engine.topology.Layer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, rate, noise_shape=None, seed=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  call(self, inputs, training=None)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Container` (one layer of abstraction above).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, **kwargs)\n",
      " |      Wrapper around self.call(), for handling internal references.\n",
      " |      \n",
      " |      If a Keras tensor is passed:\n",
      " |          - We call self._add_inbound_node().\n",
      " |          - If necessary, we `build` the layer to match\n",
      " |              the _keras_shape of the input(s).\n",
      " |          - We update the _keras_shape of every input tensor with\n",
      " |              its new shape (obtained via self.compute_output_shape).\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |          - We update the _keras_history of the output tensor(s)\n",
      " |              with the current layer.\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Can be a tensor or list/tuple of tensors.\n",
      " |          **kwargs: Additional keyword arguments to be passed to `call()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output of the layer's `call` method.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case the layer is missing shape information\n",
      " |              for its `build` call.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add losses to the layer.\n",
      " |      \n",
      " |      The loss may potentially be conditional on some inputs tensors,\n",
      " |      for instance activity losses are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          losses: loss tensor or list of loss tensors\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the losses as conditional on these inputs.\n",
      " |              If None is passed, the loss is assumed unconditional\n",
      " |              (e.g. L2 weight regularization, which only depends\n",
      " |              on the layer's weights variables, not on any inputs tensors).\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add updates to the layer.\n",
      " |      \n",
      " |      The updates may potentially be conditional on some inputs tensors,\n",
      " |      for instance batch norm updates are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          updates: update op or list of update ops\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the updates as conditional on these inputs.\n",
      " |              If None is passed, the updates are assumed unconditional.\n",
      " |  \n",
      " |  add_weight(self, name, shape, dtype=None, initializer=None, regularizer=None, trainable=True, constraint=None)\n",
      " |      Adds a weight variable to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, the name for the weight variable.\n",
      " |          shape: The shape tuple of the weight.\n",
      " |          dtype: The dtype of the weight.\n",
      " |          initializer: An Initializer instance (callable).\n",
      " |          regularizer: An optional Regularizer instance.\n",
      " |          trainable: A boolean, whether the weight should\n",
      " |              be trained via backprop or not (assuming\n",
      " |              that the layer itself is also trainable).\n",
      " |          constraint: An optional Constraint instance.\n",
      " |      \n",
      " |      # Returns\n",
      " |          The created weight variable.\n",
      " |  \n",
      " |  assert_input_compatibility(self, inputs)\n",
      " |      Checks compatibility between the layer and provided inputs.\n",
      " |      \n",
      " |      This checks that the tensor(s) `input`\n",
      " |      verify the input assumptions of the layer\n",
      " |      (if any). If not, exceptions are raised.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case of mismatch between\n",
      " |              the provided inputs and the expectations of the layer.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the layer weights.\n",
      " |      \n",
      " |      Must be implemented on all layers that have weights.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Keras tensor (future input to layer)\n",
      " |              or list/tuple of Keras tensors to reference\n",
      " |              for weight shape computations.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      # Returns\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      Assumes that the layer will be built\n",
      " |      to match that input shape provided.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An integer count.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the layer isn't yet built\n",
      " |              (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Container), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  built\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input shape tuple\n",
      " |          (or list of input shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  losses\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output tensor or list of output tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one inbound node,\n",
      " |      or if all inbound nodes have the same output shape.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output shape tuple\n",
      " |          (or list of input shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  weights\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
